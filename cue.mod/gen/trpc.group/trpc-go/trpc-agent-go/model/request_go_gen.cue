// Code generated by cue get go. DO NOT EDIT.

//cue:generate cue get go trpc.group/trpc-go/trpc-agent-go/model

package model

// Role represents the role of a message author.
#Role: string // #enumRole

#enumRole:
	#RoleSystem |
	#RoleUser |
	#RoleAssistant |
	#RoleTool

#RoleSystem:    #Role & "system"
#RoleUser:      #Role & "user"
#RoleAssistant: #Role & "assistant"
#RoleTool:      #Role & "tool"

// ThinkingEnabledKey is the key used for enabling thinking mode in API requests.
#ThinkingEnabledKey: "thinking_enabled"

// ThinkingTokensKey is the key used for thinking tokens configuration in API requests.
#ThinkingTokensKey: "thinking_tokens"

// ReasoningContentKey is the key used for reasoning content in API responses.
#ReasoningContentKey: "reasoning_content"

// Message represents a single message in a conversation.
#Message: {
	// Role is the role of the message author.
	role: #Role @go(Role)

	// Content is the message content.
	content?: string @go(Content)

	// ContentParts is the content parts for multimodal messages.
	content_parts?: [...#ContentPart] @go(ContentParts,[]ContentPart)

	// ToolID is the ID of the tool used by tool response.
	tool_id?: string @go(ToolID)

	// ToolName is the name of the tool used by tool response.
	tool_name?: string @go(ToolName)

	// ToolCalls is the optional tool calls for the message.
	tool_calls?: [...#ToolCall] @go(ToolCalls,[]ToolCall)

	// ReasoningContent is hunyuan or deepseek think content
	// - https://api-docs.deepseek.com/api/create-chat-completion#responses
	reasoning_content?: string @go(ReasoningContent)
}

// ContentType represents the type of content.
#ContentType: string // #enumContentType

#enumContentType:
	#ContentTypeText |
	#ContentTypeImage |
	#ContentTypeAudio |
	#ContentTypeFile

#ContentTypeText:  #ContentType & "text"
#ContentTypeImage: #ContentType & "image"
#ContentTypeAudio: #ContentType & "audio"
#ContentTypeFile:  #ContentType & "file"

// ContentPart represents a single content part in a multimodal message.
#ContentPart: {
	// Type is the type of content: "text", "image", "audio", "file"
	type: #ContentType @go(Type)

	// Text is the text content.
	text?: null | string @go(Text,*string)

	// Image is the image data.
	image?: null | #Image @go(Image,*Image)

	// Audio is the audio data.
	audio?: null | #Audio @go(Audio,*Audio)

	// File is the file data.
	file?: null | #File @go(File,*File)
}

// File represents file content for file input models.
#File: {
	// Name is the name of the file, used when passing the file to the model as a string.
	filename: string @go(Name)

	// Data is the raw file data, used when passing the file to the model as a string.
	data: bytes @go(Data,[]byte)

	// FileID is the ID of an uploaded file to use as input.
	file_id: string @go(FileID)

	// MimeType is the format of the file data.
	format?: string @go(MimeType)
}

// Image represents an image data for vision models.
#Image: {
	// URL is the URL of the image.
	url: string @go(URL)

	// Data is the raw image data.
	data: bytes @go(Data,[]byte)

	// Detail is the detail level: "low", "high", "auto".
	detail?: string @go(Detail)

	// Format is the format of the image data.
	format?: string @go(Format)
}

// Audio represents audio input for audio models.
#Audio: {
	// Data is the raw audio data.
	data: bytes @go(Data,[]byte)

	// Format is the format of the encoded audio data. Currently supports "wav" and "mp3".
	format: string @go(Format)
}

// GenerationConfig contains configuration for text generation.
#GenerationConfig: {
	// MaxTokens is the maximum number of tokens to generate.
	max_tokens?: null | int @go(MaxTokens,*int)

	// Temperature controls randomness (0.0 to 2.0).
	temperature?: null | float64 @go(Temperature,*float64)

	// TopP controls nucleus sampling (0.0 to 1.0).
	top_p?: null | float64 @go(TopP,*float64)

	// Stream indicates whether to stream the response.
	stream: bool @go(Stream)

	// Stop sequences where the API will stop generating further tokens.
	stop?: [...string] @go(Stop,[]string)

	// PresencePenalty penalizes new tokens based on their existing frequency.
	presence_penalty?: null | float64 @go(PresencePenalty,*float64)

	// FrequencyPenalty penalizes new tokens based on their frequency in the text so far.
	frequency_penalty?: null | float64 @go(FrequencyPenalty,*float64)

	// ReasoningEffort limits the reasoning effort for reasoning models.
	// Supported values: "low", "medium", "high".
	// Only effective for OpenAI o-series models.
	reasoning_effort?: null | string @go(ReasoningEffort,*string)

	// ThinkingEnabled enables thinking mode for Claude and Gemini models via OpenAI API.
	thinking_enabled?: null | bool @go(ThinkingEnabled,*bool)

	// ThinkingTokens controls the length of thinking for Claude and Gemini models via OpenAI API.
	thinking_tokens?: null | int @go(ThinkingTokens,*int)
}

// Request is the request to the model.
#Request: {
	// Messages is the conversation history.
	messages: [...#Message] @go(Messages,[]Message)

	#GenerationConfig

	// StructuredOutput defines how the model should produce structured output.
	// When set, the underlying model adapter may use native structured output
	// capabilities (e.g. OpenAI response_format with json_schema) to enforce
	// JSON formatting. This field is optional and provider-agnostic.
	structured_output?: null | #StructuredOutput @go(StructuredOutput,*StructuredOutput)
}

// ToolCall represents a call to a tool (function) in the model response.
#ToolCall: {
	// Type of the tool. Currently, only `function` is supported.
	type: string @go(Type)

	// Function definition for the tool
	function?: #FunctionDefinitionParam @go(Function)

	// The ID of the tool call returned by the model.
	id?: string @go(ID)

	// Index is the index of the tool call in the message for streaming responses.
	index?: null | int @go(Index,*int)
}

// FunctionDefinitionParam represents the parameters for a function definition in tool calls.
#FunctionDefinitionParam: {
	// The name of the function to be called. Must be a-z, A-Z, 0-9, or contain
	// underscores and dashes, with a maximum length of 64.
	name: string @go(Name)

	// Whether to enable strict schema adherence when generating the function call. If
	// set to true, the model will follow the exact schema defined in the `parameters`
	// field. Only a subset of JSON Schema is supported when `strict` is `true`. Learn
	// more about Structured Outputs in the
	// [function calling guide](docs/guides/function-calling).
	strict?: bool @go(Strict)

	// A description of what the function does, used by the model to choose when and
	// how to call the function.
	description?: string @go(Description)

	// Optional arguments to pass to the function, json-encoded.
	arguments?: bytes @go(Arguments,[]byte)
}

// StructuredOutputType defines the type of structured output.
#StructuredOutputType: string // #enumStructuredOutputType

#enumStructuredOutputType:
	#StructuredOutputJSONSchema

// StructuredOutputJSONSchema enables structured JSON output.
#StructuredOutputJSONSchema: #StructuredOutputType & "json_schema"

// JSONSchemaConfig defines the configuration for JSON schema structured output.
#JSONSchemaConfig: {
	// Name is the name of the structured output format.
	name?: string @go(Name)

	// Schema is the JSON schema definition.
	schema: {...} @go(Schema,map[string]interface{})

	// Strict controls whether to enforce strict schema adherence.
	strict?: bool @go(Strict)

	// Description provides context for the model about the structured output.
	description?: string @go(Description)
}

// StructuredOutput defines how the model should produce structured output.
#StructuredOutput: {
	// Type specifies the structured output type.
	type: #StructuredOutputType @go(Type)

	// JSONSchema is used when Type is StructuredOutputJSONSchema.
	json_schema?: null | #JSONSchemaConfig @go(JSONSchema,*JSONSchemaConfig)
}
